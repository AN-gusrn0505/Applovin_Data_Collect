from flask import Flask, jsonify
import os
import json
from datetime import datetime, timedelta
import pandas as pd
import requests
from io import StringIO
from google.cloud import bigquery
import time

app = Flask(__name__)

class AxonDataCollector:
    def __init__(self):
        """í™˜ê²½ë³€ìˆ˜ ë¡œë“œ ë° ì´ˆê¸°í™”"""
        # í•„ìˆ˜ í™˜ê²½ë³€ìˆ˜ ê²€ì¦
        required_env_vars = ['AXON_API_KEY', 'GCP_PROJECT_ID', 'BQ_DATASET_ID']
        missing_vars = [var for var in required_env_vars if not os.environ.get(var)]

        if missing_vars:
            raise ValueError(f"âŒ í•„ìˆ˜ í™˜ê²½ë³€ìˆ˜ ëˆ„ë½: {', '.join(missing_vars)}")

        self.api_key = os.environ['AXON_API_KEY']
        self.project_id = os.environ['GCP_PROJECT_ID']
        self.dataset_id = os.environ['BQ_DATASET_ID']

        # BigQuery í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        try:
            self.bq_client = bigquery.Client(project=self.project_id)
        except Exception as e:
            raise ValueError(f"âŒ BigQuery í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")

        # JSON í˜•ì‹ìœ¼ë¡œ ì•± ëª©ë¡ ë¡œë“œ
        apps_config = os.environ.get('APPS_CONFIG', '[]')
        try:
            self.apps = json.loads(apps_config)
            if not isinstance(self.apps, list):
                raise ValueError("APPS_CONFIGëŠ” ë¦¬ìŠ¤íŠ¸ í˜•ì‹ì´ì–´ì•¼ í•©ë‹ˆë‹¤")

            # ì•± ì„¤ì • ê²€ì¦
            for idx, app in enumerate(self.apps):
                if 'platform' not in app or 'package' not in app:
                    raise ValueError(f"ì•± {idx}: 'platform'ê³¼ 'package' í•„ë“œê°€ í•„ìš”í•©ë‹ˆë‹¤")
                if app['platform'] not in ['android', 'ios', 'fireos']:
                    raise ValueError(f"ì•± {idx}: platformì€ android, ios, fireos ì¤‘ í•˜ë‚˜ì—¬ì•¼ í•©ë‹ˆë‹¤")

            print(f"ğŸ“± ë“±ë¡ëœ ì•±: {len(self.apps)}ê°œ")
        except json.JSONDecodeError as e:
            raise ValueError(f"âŒ APPS_CONFIG JSON íŒŒì‹± ì‹¤íŒ¨: {str(e)}")
    
    def check_data_exists(self, table_name, date, application=None, platform=None):
        """
        íŠ¹ì • ë‚ ì§œ ë°ì´í„° ì¡´ì¬ ì—¬ë¶€ í™•ì¸

        Args:
            table_name: í…Œì´ë¸”ëª…
            date: ë‚ ì§œ
            application: ì•± íŒ¨í‚¤ì§€ëª… (user_level_ad_revenueë§Œ í•´ë‹¹)
            platform: í”Œë«í¼ (user_level_ad_revenueë§Œ í•´ë‹¹)
        """
        # user_level_ad_revenueëŠ” ì•±ë³„ë¡œ í™•ì¸
        if table_name == 'user_level_ad_revenue' and application and platform:
            query = f"""
            SELECT COUNT(*) as cnt
            FROM `{self.project_id}.{self.dataset_id}.{table_name}`
            WHERE report_date = '{date}'
              AND application = '{application}'
              AND platform = '{platform}'
            """
        else:
            # revenue_reportingì€ ë‚ ì§œë³„ë¡œ í™•ì¸
            query = f"""
            SELECT COUNT(*) as cnt
            FROM `{self.project_id}.{self.dataset_id}.{table_name}`
            WHERE report_date = '{date}'
            """

        try:
            result = self.bq_client.query(query).result()
            count = list(result)[0].cnt
            return count > 0
        except Exception as e:
            print(f"    âš ï¸ í…Œì´ë¸” í™•ì¸ ì‹¤íŒ¨ ({table_name}): {str(e)}")
            return False
    
    def delete_date_data(self, table_name, date, application=None, platform=None):
        """
        íŠ¹ì • ë‚ ì§œ ë°ì´í„° ì‚­ì œ (ì—…ë°ì´íŠ¸ ì „)

        Args:
            table_name: í…Œì´ë¸”ëª…
            date: ë‚ ì§œ
            application: ì•± íŒ¨í‚¤ì§€ëª… (user_level_ad_revenueë§Œ í•´ë‹¹)
            platform: í”Œë«í¼ (user_level_ad_revenueë§Œ í•´ë‹¹)
        """
        # user_level_ad_revenueëŠ” ì•±ë³„ë¡œ ì‚­ì œ (ê°™ì€ ë‚ ì§œì˜ ë‹¤ë¥¸ ì•± ë³´í˜¸)
        if table_name == 'user_level_ad_revenue' and application and platform:
            query = f"""
            DELETE FROM `{self.project_id}.{self.dataset_id}.{table_name}`
            WHERE report_date = '{date}'
              AND application = '{application}'
              AND platform = '{platform}'
            """
            print(f"    ğŸ—‘ï¸ ê¸°ì¡´ ë°ì´í„° ì‚­ì œ: {date} / {application} ({platform})")
        else:
            # revenue_reportingì€ ë‚ ì§œë³„ë¡œ ì‚­ì œ
            query = f"""
            DELETE FROM `{self.project_id}.{self.dataset_id}.{table_name}`
            WHERE report_date = '{date}'
            """
            print(f"    ğŸ—‘ï¸ ê¸°ì¡´ ë°ì´í„° ì‚­ì œ: {date}")

        try:
            job = self.bq_client.query(query)
            job.result()
        except Exception as e:
            print(f"    âŒ ì‚­ì œ ì‹¤íŒ¨: {str(e)}")
    
    def fetch_user_level_data(self, date, platform, application, aggregated=False):
        """
        User-Level Ad Revenue API í˜¸ì¶œ

        Args:
            date: ì¡°íšŒ ë‚ ì§œ (YYYY-MM-DD)
            platform: android, ios, fireos
            application: íŒ¨í‚¤ì§€ëª…
            aggregated: False=ë…¸ì¶œë³„(ì¶”ì²œ), True=ìœ ì €ë³„ ì§‘ê³„
        """
        data_type_str = "ìœ ì €ë³„ ì§‘ê³„" if aggregated else "ë…¸ì¶œë³„"
        print(f"  ğŸ“¥ User-Level ({data_type_str}) ë°ì´í„° ì¡°íšŒ: {application} ({platform})")

        url = "https://r.applovin.com/max/userAdRevenueReport"
        params = {
            'api_key': self.api_key,
            'date': date,
            'platform': platform,
            'application': application,
            'aggregated': 'true' if aggregated else 'false'
        }

        try:
            response = requests.get(url, params=params, timeout=60)

            # HTTP ìƒíƒœ ì½”ë“œë³„ ì²˜ë¦¬
            if response.status_code == 429:
                print(f"    âš ï¸ Rate limit ì´ˆê³¼ (429) - 60ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„")
                time.sleep(60)
                response = requests.get(url, params=params, timeout=60)
            elif response.status_code == 401:
                print(f"    âŒ ì¸ì¦ ì‹¤íŒ¨ (401) - API í‚¤ í™•ì¸ í•„ìš”")
                return None
            elif response.status_code == 403:
                print(f"    âŒ ì ‘ê·¼ ê±°ë¶€ (403) - ê¶Œí•œ í™•ì¸ í•„ìš”")
                return None
            elif response.status_code >= 500:
                print(f"    âš ï¸ ì„œë²„ ì—ëŸ¬ ({response.status_code}) - 30ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„")
                time.sleep(30)
                response = requests.get(url, params=params, timeout=60)

            response.raise_for_status()
            data = response.json()

            # 3ê°€ì§€ URL ìš°ì„ ìˆœìœ„: ad_revenue_report_url (ì „ì²´) > url > fb_estimated_revenue_url
            csv_url = data.get('ad_revenue_report_url') or data.get('url') or data.get('fb_estimated_revenue_url')

            # data_source ê¸°ë¡
            if data.get('ad_revenue_report_url'):
                data_source = 'ad_revenue_report_url'
            elif data.get('url'):
                data_source = 'url'
            elif data.get('fb_estimated_revenue_url'):
                data_source = 'fb_estimated_revenue_url'
            else:
                print(f"    âš ï¸ CSV URL ì—†ìŒ (ì •ìƒ - ë°ì´í„° ì—†ëŠ” ë‚ )")
                return None

            # S3 URLì€ 1ì‹œê°„ ë‚´ ë§Œë£Œë˜ë¯€ë¡œ ì¦‰ì‹œ ë‹¤ìš´ë¡œë“œ
            csv_response = requests.get(csv_url, timeout=120)
            csv_response.raise_for_status()

            df = pd.read_csv(StringIO(csv_response.text))

            if len(df) == 0:
                print(f"    âš ï¸ ë°ì´í„° ì—†ìŒ (ì •ìƒ - ì‹ ê·œ ì•±ì´ê±°ë‚˜ íŠ¸ë˜í”½ ì—†ìŒ)")
                return None

            # ì»¬ëŸ¼ëª… ì •ê·œí™” (ëŒ€ì†Œë¬¸ì, ê³µë°± í†µì¼)
            df.columns = df.columns.str.strip().str.lower().str.replace(' ', '_')

            # ë™ì  ì»¬ëŸ¼ ë§¤í•‘ (API ì‘ë‹µì´ ì¼ê´€ì„± ì—†ì„ ìˆ˜ ìˆìŒ)
            column_mapping = {}
            for col in df.columns:
                if col in ['date', 'timestamp']:
                    column_mapping[col] = 'impression_timestamp'
                elif col in ['ad_unit_id', 'adunitid']:
                    column_mapping[col] = 'ad_unit_id'
                elif col in ['ad_unit_name', 'adunitname']:
                    column_mapping[col] = 'ad_unit_name'
                elif col in ['ad_format', 'adformat']:
                    column_mapping[col] = 'ad_format'
                elif col in ['ad_placement', 'adplacement']:
                    column_mapping[col] = 'ad_placement'
                elif col in ['device_type', 'devicetype']:
                    column_mapping[col] = 'device_type'
                elif col in ['user_id', 'userid']:
                    column_mapping[col] = 'user_id'
                elif col in ['custom_data', 'customdata']:
                    column_mapping[col] = 'custom_data'

            df.rename(columns=column_mapping, inplace=True)

            # í•„ìˆ˜ ì»¬ëŸ¼ ì¶”ê°€
            df['report_date'] = pd.to_datetime(date).date()
            df['application'] = application
            df['package_name'] = application
            df['platform'] = platform
            df['loaded_at'] = datetime.utcnow()
            df['data_source'] = data_source

            # data_type êµ¬ë¶„ (impressions ì»¬ëŸ¼ ìœ ë¬´ë¡œ íŒë‹¨)
            if 'impressions' in df.columns:
                df['data_type'] = 'user_aggregated'
            else:
                df['data_type'] = 'impression'

            # íƒ€ì… ë³€í™˜
            if 'impression_timestamp' in df.columns:
                df['impression_timestamp'] = pd.to_datetime(df['impression_timestamp'], errors='coerce')

            if 'revenue' in df.columns:
                df['revenue'] = pd.to_numeric(df['revenue'], errors='coerce')

            if 'impressions' in df.columns:
                df['impressions'] = pd.to_numeric(df['impressions'], errors='coerce').fillna(0).astype(int)

            # NULL ì²˜ë¦¬ (IDFA, User ID ë“±ì€ NULL ê°€ëŠ¥)
            # pandasì˜ NaNì„ Noneìœ¼ë¡œ ë³€í™˜ (BigQueryëŠ” Noneì„ NULLë¡œ ì²˜ë¦¬)
            df = df.where(pd.notnull(df), None)

            record_count = len(df)
            print(f"    âœ… {record_count}ê°œ ë ˆì½”ë“œ ({data_source})")
            return df

        except Exception as e:
            print(f"    âŒ ì—ëŸ¬: {str(e)}")
            import traceback
            print(f"    ğŸ“ ìƒì„¸: {traceback.format_exc()}")
            return None


    def fetch_revenue_reporting_basic(self, date):
        """Revenue Reporting API í˜¸ì¶œ - Basic (requests í¬í•¨)"""
        print(f"  ğŸ“Š Revenue Reporting (Basic) ë°ì´í„° ì¡°íšŒ")

        url = "https://r.applovin.com/maxReport"
        params = {
            'api_key': self.api_key,
            'start': date,
            'end': date,
            'columns': 'day,application,package_name,store_id,platform,country,device_type,'
                    'ad_format,has_idfa,impressions,estimated_revenue,ecpm,requests',
            'format': 'csv',
            'not_zero': 1
        }

        try:
            response = requests.get(url, params=params, timeout=60)

            # HTTP ìƒíƒœ ì½”ë“œë³„ ì²˜ë¦¬
            if response.status_code == 429:
                print(f"    âš ï¸ Rate limit ì´ˆê³¼ (429) - 60ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„")
                time.sleep(60)
                response = requests.get(url, params=params, timeout=60)
            elif response.status_code == 401:
                print(f"    âŒ ì¸ì¦ ì‹¤íŒ¨ (401) - API í‚¤ í™•ì¸ í•„ìš”")
                return None
            elif response.status_code == 403:
                print(f"    âŒ ì ‘ê·¼ ê±°ë¶€ (403) - ê¶Œí•œ í™•ì¸ í•„ìš”")
                return None
            elif response.status_code >= 500:
                print(f"    âš ï¸ ì„œë²„ ì—ëŸ¬ ({response.status_code}) - 30ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„")
                time.sleep(30)
                response = requests.get(url, params=params, timeout=60)

            response.raise_for_status()

            df = pd.read_csv(StringIO(response.text))

            if len(df) == 0:
                print(f"    âš ï¸ ë°ì´í„° ì—†ìŒ")
                return None

            # ì»¬ëŸ¼ëª… ì†Œë¬¸ì ë³€í™˜
            df.columns = df.columns.str.lower()

            # ì»¬ëŸ¼ rename
            df.rename(columns={'day': 'report_date'}, inplace=True)

            # í•„ìˆ˜ ì»¬ëŸ¼ ì¶”ê°€
            df['query_type'] = 'basic'
            df['loaded_at'] = datetime.utcnow()

            # ì•ˆì „í•œ íƒ€ì… ë³€í™˜
            if 'report_date' in df.columns:
                df['report_date'] = pd.to_datetime(df['report_date']).dt.date
            else:
                print(f"    âŒ 'report_date' ì»¬ëŸ¼ ì—†ìŒ!")
                return None

            # ìˆ«ìí˜• ì»¬ëŸ¼ ë³€í™˜
            if 'impressions' in df.columns:
                df['impressions'] = pd.to_numeric(df['impressions'], errors='coerce').fillna(0).astype(int)
            if 'estimated_revenue' in df.columns:
                df['estimated_revenue'] = pd.to_numeric(df['estimated_revenue'], errors='coerce').fillna(0).astype(float)
            if 'ecpm' in df.columns:
                df['ecpm'] = pd.to_numeric(df['ecpm'], errors='coerce').fillna(0).astype(float)
            if 'requests' in df.columns:
                df['requests'] = pd.to_numeric(df['requests'], errors='coerce').fillna(0).astype(int)

            # boolean ì»¬ëŸ¼ ë³€í™˜
            if 'has_idfa' in df.columns:
                df['has_idfa'] = df['has_idfa'].astype(str).str.lower().isin(['true', '1', 'yes'])
            if 'max_ad_unit_test' in df.columns:
                df['max_ad_unit_test'] = df['max_ad_unit_test'].astype(str).str.lower().isin(['true', '1', 'yes'])

            print(f"    âœ… {len(df)}ê°œ Basic ë ˆì½”ë“œ")
            return df

        except Exception as e:
            print(f"    âŒ ì—ëŸ¬: {str(e)}")
            import traceback
            print(f"    ğŸ“ ìƒì„¸: {traceback.format_exc()}")
            return None

    def fetch_revenue_reporting_network(self, date):
        """Revenue Reporting API í˜¸ì¶œ - Network Detail (attempts, responses, fill_rate í¬í•¨)"""
        print(f"  ğŸ“Š Revenue Reporting (Network Detail) ë°ì´í„° ì¡°íšŒ")

        url = "https://r.applovin.com/maxReport"
        params = {
            'api_key': self.api_key,
            'start': date,
            'end': date,
            'columns': 'day,application,package_name,platform,country,device_type,'
                    'ad_format,network,network_placement,custom_network_name,has_idfa,'
                    'impressions,estimated_revenue,ecpm,attempts,responses,fill_rate',
            'format': 'csv',
            'not_zero': 1
        }

        try:
            response = requests.get(url, params=params, timeout=60)

            # HTTP ìƒíƒœ ì½”ë“œë³„ ì²˜ë¦¬
            if response.status_code == 429:
                print(f"    âš ï¸ Rate limit ì´ˆê³¼ (429) - 60ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„")
                time.sleep(60)
                response = requests.get(url, params=params, timeout=60)
            elif response.status_code == 401:
                print(f"    âŒ ì¸ì¦ ì‹¤íŒ¨ (401) - API í‚¤ í™•ì¸ í•„ìš”")
                return None
            elif response.status_code == 403:
                print(f"    âŒ ì ‘ê·¼ ê±°ë¶€ (403) - ê¶Œí•œ í™•ì¸ í•„ìš”")
                return None
            elif response.status_code >= 500:
                print(f"    âš ï¸ ì„œë²„ ì—ëŸ¬ ({response.status_code}) - 30ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„")
                time.sleep(30)
                response = requests.get(url, params=params, timeout=60)

            response.raise_for_status()

            df = pd.read_csv(StringIO(response.text))

            if len(df) == 0:
                print(f"    âš ï¸ ë°ì´í„° ì—†ìŒ")
                return None

            # ì»¬ëŸ¼ëª… ì†Œë¬¸ì ë³€í™˜
            df.columns = df.columns.str.lower()

            # ì»¬ëŸ¼ rename
            df.rename(columns={'day': 'report_date'}, inplace=True)

            # í•„ìˆ˜ ì»¬ëŸ¼ ì¶”ê°€
            df['query_type'] = 'network_detail'
            df['loaded_at'] = datetime.utcnow()

            # ì•ˆì „í•œ íƒ€ì… ë³€í™˜
            if 'report_date' in df.columns:
                df['report_date'] = pd.to_datetime(df['report_date']).dt.date
            else:
                print(f"    âŒ 'report_date' ì»¬ëŸ¼ ì—†ìŒ!")
                return None

            # ìˆ«ìí˜• ì»¬ëŸ¼ ë³€í™˜
            if 'impressions' in df.columns:
                df['impressions'] = pd.to_numeric(df['impressions'], errors='coerce').fillna(0).astype(int)
            if 'estimated_revenue' in df.columns:
                df['estimated_revenue'] = pd.to_numeric(df['estimated_revenue'], errors='coerce').fillna(0).astype(float)
            if 'ecpm' in df.columns:
                df['ecpm'] = pd.to_numeric(df['ecpm'], errors='coerce').fillna(0).astype(float)
            if 'attempts' in df.columns:
                df['attempts'] = pd.to_numeric(df['attempts'], errors='coerce').fillna(0).astype(int)
            if 'responses' in df.columns:
                df['responses'] = pd.to_numeric(df['responses'], errors='coerce').fillna(0).astype(int)
            if 'fill_rate' in df.columns:
                df['fill_rate'] = pd.to_numeric(df['fill_rate'], errors='coerce').fillna(0).astype(float)

            # boolean ì»¬ëŸ¼ ë³€í™˜
            if 'has_idfa' in df.columns:
                df['has_idfa'] = df['has_idfa'].astype(str).str.lower().isin(['true', '1', 'yes'])

            print(f"    âœ… {len(df)}ê°œ Network Detail ë ˆì½”ë“œ")
            return df

        except Exception as e:
            print(f"    âŒ ì—ëŸ¬: {str(e)}")
            import traceback
            print(f"    ğŸ“ ìƒì„¸: {traceback.format_exc()}")
            return None



    def load_to_bigquery(self, df, table_name, date, force_update=False, application=None, platform=None):
        """
        DataFrameì„ BigQueryì— ì ì¬

        Args:
            df: ì ì¬í•  ë°ì´í„°
            table_name: í…Œì´ë¸”ëª…
            date: ë‚ ì§œ (ì¤‘ë³µ ì²´í¬ìš©)
            force_update: Trueë©´ ê¸°ì¡´ ë°ì´í„° ì‚­ì œ í›„ ì¬ì ì¬
            application: ì•± íŒ¨í‚¤ì§€ëª… (user_level_ad_revenueìš©)
            platform: í”Œë«í¼ (user_level_ad_revenueìš©)
        """
        if df is None or len(df) == 0:
            return

        table_ref = f"{self.project_id}.{self.dataset_id}.{table_name}"

        # ë°ì´í„° ì¡´ì¬ ì—¬ë¶€ í™•ì¸ (user_level_ad_revenueëŠ” ì•±ë³„ë¡œ ì²´í¬)
        exists = self.check_data_exists(table_name, date, application, platform)

        if exists and not force_update:
            if table_name == 'user_level_ad_revenue' and application and platform:
                print(f"    â­ï¸ ì´ë¯¸ ë°ì´í„° ì¡´ì¬, ìŠ¤í‚µ: {date} / {application} ({platform}) â†’ {table_name}")
            else:
                print(f"    â­ï¸ ì´ë¯¸ ë°ì´í„° ì¡´ì¬, ìŠ¤í‚µ: {date} â†’ {table_name}")
            return

        if exists and force_update:
            print(f"    ğŸ”„ ë°ì´í„° ì—…ë°ì´íŠ¸ ëª¨ë“œ: {date}")
            self.delete_date_data(table_name, date, application, platform)

        job_config = bigquery.LoadJobConfig(write_disposition="WRITE_APPEND")

        try:
            job = self.bq_client.load_table_from_dataframe(df, table_ref, job_config=job_config)
            job.result()
            print(f"    ğŸ’¾ BigQuery ì ì¬ ì™„ë£Œ: {len(df)}ê°œ â†’ {table_name}")
        except Exception as e:
            print(f"    âŒ BigQuery ì ì¬ ì‹¤íŒ¨: {str(e)}")
            import traceback
            print(f"    ğŸ“ ìƒì„¸: {traceback.format_exc()}")
    
    def collect_daily_data(self, date=None, apps=None, force_update=False):
        """
        ì „ì²´ ë°ì´í„° ìˆ˜ì§‘ íŒŒì´í”„ë¼ì¸

        Args:
            date: ìˆ˜ì§‘ ë‚ ì§œ (ê¸°ë³¸ê°’: ì–´ì œ)
            apps: ì•± ëª©ë¡ (ê¸°ë³¸ê°’: í™˜ê²½ë³€ìˆ˜)
            force_update: ê¸°ì¡´ ë°ì´í„° ìˆì–´ë„ ì—…ë°ì´íŠ¸

        Returns:
            dict: ìˆ˜ì§‘ ê²°ê³¼ í†µê³„
        """
        if date is None:
            date = (datetime.utcnow() - timedelta(days=1)).strftime('%Y-%m-%d')

        print(f"\n{'='*50}")
        print(f"ğŸ“… {date} ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘")
        if force_update:
            print(f"ğŸ”„ ì—…ë°ì´íŠ¸ ëª¨ë“œ: ê¸°ì¡´ ë°ì´í„° ë®ì–´ì“°ê¸°")
        print(f"{'='*50}")

        # í™˜ê²½ë³€ìˆ˜ì—ì„œ ì•± ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        if apps is None:
            apps = self.apps

        if not apps:
            print("âš ï¸ ë“±ë¡ëœ ì•±ì´ ì—†ìŠµë‹ˆë‹¤. APPS_CONFIG í™˜ê²½ë³€ìˆ˜ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
            return {'success': False, 'message': 'ì•± ëª©ë¡ ì—†ìŒ'}

        # í†µê³„ ì¹´ìš´í„°
        stats = {
            'user_level_success': 0,
            'user_level_failed': 0,
            'user_level_no_data': 0,
            'revenue_basic_success': False,
            'revenue_network_success': False
        }

        # User-Level ë°ì´í„° (ë…¸ì¶œë³„ - aggregated=false)
        print(f"\n1ï¸âƒ£ User-Level Ad Revenue ìˆ˜ì§‘ (ë…¸ì¶œë³„)")
        for app in apps:
            try:
                df = self.fetch_user_level_data(
                    date=date,
                    platform=app['platform'],
                    application=app['package'],
                    aggregated=False  # ë…¸ì¶œë³„ ë°ì´í„° (ì¶”ì²œ)
                )
                if df is not None:
                    # ì•±ë³„ë¡œ ê°œë³„ ì ì¬ (ì¤‘ë³µ ë°©ì§€ë¥¼ ìœ„í•´)
                    self.load_to_bigquery(
                        df,
                        'user_level_ad_revenue',
                        date,
                        force_update,
                        application=app['package'],
                        platform=app['platform']
                    )
                    stats['user_level_success'] += 1
                else:
                    stats['user_level_no_data'] += 1
            except Exception as e:
                print(f"    âŒ {app['package']} ({app['platform']}) ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
                stats['user_level_failed'] += 1

        # Revenue Reporting - Basic
        print(f"\n2ï¸âƒ£ Revenue Reporting ìˆ˜ì§‘")
        try:
            df_basic = self.fetch_revenue_reporting_basic(date)
            if df_basic is not None:
                self.load_to_bigquery(df_basic, 'revenue_reporting', date, force_update)
                stats['revenue_basic_success'] = True
        except Exception as e:
            print(f"    âŒ Revenue Reporting (Basic) ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")

        # Revenue Reporting - Network Detail
        try:
            df_network = self.fetch_revenue_reporting_network(date)
            if df_network is not None:
                self.load_to_bigquery(df_network, 'revenue_reporting', date, force_update)
                stats['revenue_network_success'] = True
        except Exception as e:
            print(f"    âŒ Revenue Reporting (Network) ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")

        # ê²°ê³¼ ì¶œë ¥
        print(f"\n{'='*50}")
        print(f"âœ… {date} ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ!")
        print(f"ğŸ“Š User-Level: ì„±ê³µ {stats['user_level_success']}, "
              f"ë°ì´í„°ì—†ìŒ {stats['user_level_no_data']}, "
              f"ì‹¤íŒ¨ {stats['user_level_failed']}")
        print(f"ğŸ“Š Revenue Reporting: Basic {'âœ…' if stats['revenue_basic_success'] else 'âŒ'}, "
              f"Network {'âœ…' if stats['revenue_network_success'] else 'âŒ'}")
        print(f"{'='*50}\n")

        return stats
    
    def backfill_data(self, days=45):
        """
        ê³¼ê±° ë°ì´í„° ì´ˆê¸° ì ì¬ (45ì¼)

        Args:
            days: ê³¼ê±° ë©°ì¹ ì¹˜ ë°ì´í„° ìˆ˜ì§‘

        Returns:
            dict: ì „ì²´ ìˆ˜ì§‘ ê²°ê³¼ í†µê³„
        """
        print(f"\n{'ğŸ”¥'*25}")
        print(f"ğŸ”¥ ì´ˆê¸° ë°ì´í„° ì ì¬: ê³¼ê±° {days}ì¼")
        print(f"{'ğŸ”¥'*25}\n")

        today = datetime.utcnow()

        # ì „ì²´ í†µê³„
        total_stats = {
            'total_days': days,
            'success_days': 0,
            'failed_days': 0,
            'start_time': datetime.utcnow()
        }

        for i in range(days, 0, -1):
            try:
                target_date = (today - timedelta(days=i)).strftime('%Y-%m-%d')

                # ì§„í–‰ë¥  í‘œì‹œ
                progress = ((days - i + 1) / days) * 100
                print(f"ğŸ“ˆ ì§„í–‰ë¥ : {progress:.1f}% ({days - i + 1}/{days})")

                stats = self.collect_daily_data(date=target_date, force_update=False)

                # ì„±ê³µ ì—¬ë¶€ íŒë‹¨
                if stats and (stats.get('user_level_success', 0) > 0 or
                             stats.get('revenue_basic_success', False) or
                             stats.get('revenue_network_success', False)):
                    total_stats['success_days'] += 1
                else:
                    total_stats['failed_days'] += 1

            except Exception as e:
                print(f"âŒ {target_date} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
                total_stats['failed_days'] += 1

        total_stats['end_time'] = datetime.utcnow()
        total_stats['duration'] = (total_stats['end_time'] - total_stats['start_time']).total_seconds()

        # ê²°ê³¼ ìš”ì•½
        print(f"\n{'ğŸ‰'*25}")
        print(f"ğŸ‰ ì´ˆê¸° ì ì¬ ì™„ë£Œ: {days}ì¼ì¹˜ ë°ì´í„°")
        print(f"ğŸ“Š ì„±ê³µ: {total_stats['success_days']}ì¼, ì‹¤íŒ¨: {total_stats['failed_days']}ì¼")
        print(f"â±ï¸ ì†Œìš” ì‹œê°„: {total_stats['duration']:.1f}ì´ˆ ({total_stats['duration']/60:.1f}ë¶„)")
        print(f"{'ğŸ‰'*25}\n")

        return total_stats

# Cloud Run ì—”íŠ¸ë¦¬í¬ì¸íŠ¸
@app.route('/', methods=['GET', 'POST'])
def run_collection():
    """Cloud Schedulerì—ì„œ í˜¸ì¶œ (ì¼ì¼ ì—…ë°ì´íŠ¸)"""
    try:
        print("ğŸ“¥ ì¼ì¼ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘")
        collector = AxonDataCollector()
        
        # ì–´ì œ ë°ì´í„°ë§Œ ìˆ˜ì§‘ (ì¤‘ë³µ ì²´í¬ í¬í•¨)
        collector.collect_daily_data(force_update=False)
        
        return jsonify({'status': 'success', 'time': datetime.utcnow().isoformat()}), 200
    except Exception as e:
        print(f"âŒ ì—ëŸ¬: {str(e)}")
        return jsonify({'status': 'error', 'message': str(e)}), 500

@app.route('/backfill', methods=['POST'])
def backfill():
    """ì´ˆê¸° 45ì¼ ë°ì´í„° ì ì¬ (ìˆ˜ë™ í˜¸ì¶œìš©)"""
    try:
        print("ğŸ”¥ ì´ˆê¸° ë°ì´í„° ì ì¬ ì‹œì‘")
        collector = AxonDataCollector()
        collector.backfill_data(days=45)
        return jsonify({'status': 'success', 'message': '45ì¼ ë°ì´í„° ì ì¬ ì™„ë£Œ'}), 200
    except Exception as e:
        print(f"âŒ ì—ëŸ¬: {str(e)}")
        return jsonify({'status': 'error', 'message': str(e)}), 500

@app.route('/force-update', methods=['POST'])
def force_update():
    """ê°•ì œ ì—…ë°ì´íŠ¸ (ì–´ì œ ë°ì´í„° ì¬ìˆ˜ì§‘)"""
    try:
        print("ğŸ”„ ê°•ì œ ì—…ë°ì´íŠ¸ ì‹œì‘")
        collector = AxonDataCollector()
        collector.collect_daily_data(force_update=True)
        return jsonify({'status': 'success', 'message': 'ë°ì´í„° ê°•ì œ ì—…ë°ì´íŠ¸ ì™„ë£Œ'}), 200
    except Exception as e:
        print(f"âŒ ì—ëŸ¬: {str(e)}")
        return jsonify({'status': 'error', 'message': str(e)}), 500

if __name__ == "__main__":
    app.run(host='0.0.0.0', port=int(os.environ.get('PORT', 8080)))